{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]},"accelerator":"GPU","gpuClass":"standard"},"nbformat_minor":0,"nbformat":4,"cells":[{"cell_type":"markdown","source":["# Advanced Certification Program in Computational Data Science\n","## A program by IISc and TalentSprint\n","### Mini Project Notebook: Employee Attrition Prediction"],"metadata":{"id":"hTplQkOMsKhd"}},{"cell_type":"markdown","source":["## **Note:** This notebook is part of an in-house Kaggle competition"],"metadata":{"id":"WAJK03OtjDAB"}},{"cell_type":"markdown","source":["## Problem Statement"],"metadata":{"id":"w9wsH4KikGdd"}},{"cell_type":"markdown","source":["To predict employee attrition using CatBoost and XgBoost"],"metadata":{"id":"Bmh48BKlkIlm"}},{"cell_type":"markdown","source":["## Learning Objectives"],"metadata":{"id":"8N0iS4ipU_XM"}},{"cell_type":"markdown","source":["At the end of the experiment, you will be able to\n","\n","* explore the employee attrition dataset\n","* apply CatBoost and XgBoost on the dataset\n","* tune the model hyperparameters to improve accuracy\n","* evaluate the model using suitable metrics\n"],"metadata":{"id":"K8OXq65pVDDS"}},{"cell_type":"markdown","source":["## Introduction\n","\n","Employee attrition is the gradual reduction in employee numbers. Employee attrition happens when the size of your workforce diminishes over time. This means that employees are leaving faster than they are hired. Employee attrition happens when employees retire, resign, or simply aren't replaced.\n","Although employee attrition can be company-wide, it may also be confined to specific parts of a business.\n","\n","Employee attrition can happen for several reasons. These include unhappiness about employee benefits or the pay structure, a lack of employee development opportunities, and even poor conditions in the workplace.\n","\n","To know more about the factors that lead to employee attrition, refer [here](https://www.betterup.com/blog/employee-attrition#:~:text=Employee%20attrition%20is%20the%20gradual,or%20simply%20aren't%20replaced).\n"],"metadata":{"id":"GYxPNsZuYcGk"}},{"cell_type":"markdown","source":["**Gradient Boosted Decision Trees**\n","\n","* Gradient boosted decision trees (GBDTs) are one of the most important machine learning models.\n","\n","* GBDTs originate from AdaBoost, an algorithm that ensembles weak learners and uses the majority vote, weighted by their individual accuracy, to solve binary classification problems. The weak learners in this case are decision trees with a single split, called decision stumps.\n","\n","* Some of the widely used gradient boosted decision trees are XgBoost, CatBoost and LightGBM."],"metadata":{"id":"dsJP8R-j7tO8"}},{"cell_type":"markdown","source":["## Dataset\n","\n","The dataset used for this mini-project is [HR Employee Attrition dataset](https://data.world/aaizemberg/hr-employee-attrition). This dataset is synthetically created by IBM data scientists. There are 35 features and 1470 records.\n","\n","There are numerical features such as:\n","\n","* Age\n","* DistanceFromHome\n","* EmployeeNumber\n","* PerformanceRating\n","\n","There are several categorical features such as:\n","* JobRole\n","* EducationField\n","* Department\n","* BusinessTravel\n","\n","Dependent or target feature is 'attrition' which has values as Yes/No."],"metadata":{"id":"YC0AF58YH-cn"}},{"cell_type":"markdown","source":["### **Kaggle Competition**"],"metadata":{"id":"QrVGOVDsya0-"}},{"cell_type":"markdown","source":["Please refer to the link for viewing the\n","[Kaggle Competition Document](https://drive.google.com/file/d/1c7PrbKrURFcnEB61dSoS9cBnUUVhhj-l/view?usp=drive_link) and join the Kaggle Competition using the hyperlink given in this document under '*Kaggle* Competition site'."],"metadata":{"id":"fad4_EbCyfbg"}},{"cell_type":"markdown","source":["## Grading = 10 Points"],"metadata":{"id":"qkSHqm24yzOL"}},{"cell_type":"code","metadata":{"id":"812a816f","cellView":"form"},"source":["#@title Download the data\n","!wget -qq https://cdn.iisc.talentsprint.com/CDS/MiniProjects/hr_employee_attrition_train.csv\n","print(\"Data Downloaded Successfuly!!\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Install CatBoost"],"metadata":{"id":"1BJzstlcLh4k"}},{"cell_type":"code","source":["!pip -qq install catboost"],"metadata":{"id":"BYeUGMBZeqtL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Import Required Packages"],"metadata":{"id":"1TmXyc2bRFvM"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","from matplotlib import pyplot as plt\n","from sklearn.metrics import roc_auc_score, accuracy_score, confusion_matrix, f1_score\n","from sklearn.model_selection import train_test_split\n","from lightgbm import LGBMClassifier\n","from xgboost import XGBClassifier\n","from catboost import CatBoostClassifier, metrics\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","plt.style.use('fivethirtyeight')\n","pd.set_option('display.max_columns', 100)\n","%matplotlib inline"],"metadata":{"_uuid":"3f4d5f2c0b147e47776e71922cadb41524cb151b","trusted":true,"id":"v50DDzl0CEVk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Load the Dataset"],"metadata":{"id":"0E7JUtgDYBDL"}},{"cell_type":"markdown","source":["**Exercise 1: Read the dataset [0.5 Mark]**\n","\n","**Hint:** pd.read_csv()"],"metadata":{"id":"xhB7KfG7lAi6"}},{"cell_type":"code","source":["# read the dataset\n","# YOUR CODE HERE"],"metadata":{"id":"82VkFRBVSbG7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Check the shape of dataframe.\n","# YOUR CODE HERE"],"metadata":{"id":"L6QL6HbTZLjw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["There can be more than one file to read as this is introduced as a competition, dataset has one file for training the model. Their can be other files as one containing the test features and the other can be the true labels."],"metadata":{"id":"BHxgkAr_4grD"}},{"cell_type":"markdown","source":["## Data Exploration\n","\n","- Check for missing values\n","- Check for consistent data type across a feature\n","- Check for outliers or inconsistencies in data columns\n","- Check for correlated features\n","- Do we have a target label imbalance\n","- How our independent variables are distributed relative to our target label\n","- Are there features that have strong linear or monotonic relationships? Making correlation heatmaps makes it easy to identify possible collinearity"],"metadata":{"_uuid":"07244b5b58d56fb4ac89efc5541074263a150ce5","id":"5JgkRXxYCEVn"}},{"cell_type":"markdown","source":["**Exercise 2: Create a `List` of numerical and categorical columns. Display a statistical description of the dataset. Remove missing values (if any) [0.5 Mark]**"],"metadata":{"id":"WNypN2YmlpwG"}},{"cell_type":"markdown","source":["**Hint:** Use `for` to iterate through each column."],"metadata":{"id":"GuQKmcv0qLWo"}},{"cell_type":"code","source":["# YOUR CODE HERE"],"metadata":{"id":"rOHYyNvXRwHz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["First, we want to get a sense of our data:\n","- What features have the most divergent distributions based on target class\n","- Do we have a target label imbalance\n","- How our independent variables are distributed relative to our target label\n","- Are there features that have strong linear or monotonic relationships, making correlation heatmaps makes it easy to identify possible colinearity"],"metadata":{"id":"-5LDX4tYR6Vs"}},{"cell_type":"markdown","source":["### Check for outliers"],"metadata":{"id":"T5mUbdCMKBP8"}},{"cell_type":"markdown","source":["**Exercise 3: Create a box plot to check for outliers [0.5 Mark]**"],"metadata":{"id":"cYTnAs5UqlVn"}},{"cell_type":"code","source":["# Check for outliers\n","# YOUR CODE HERE"],"metadata":{"id":"OYTxh7gtFqyC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Handling outliers"],"metadata":{"id":"42cBMGHQQOWP"}},{"cell_type":"markdown","source":["**Exercise 4: Use lower bound as 25% and upper bound as 75% to handle the outliers [0.5 Mark]**"],"metadata":{"id":"ei63U2m7qyGA"}},{"cell_type":"code","source":["# YOUR CODE HERE"],"metadata":{"id":"oT3yOFPoH0SH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Recheck for outliers\n","# YOUR CODE HERE"],"metadata":{"id":"QvrMPhTtJTYP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Target label imbalance"],"metadata":{"id":"_ha6PPo2iCAM"}},{"cell_type":"markdown","source":["**Exercise 5: Check if there is an imbalance in target label [0.5 Mark]**"],"metadata":{"id":"ryNwfdldrR0j"}},{"cell_type":"markdown","source":["**Hint:** Use value_counts()"],"metadata":{"id":"j17VKVdnrb3R"}},{"cell_type":"code","source":["# Count of unique values in Attrition column\n","# YOUR CODE HERE"],"metadata":{"id":"y1gsAjfLbi2Z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Plot barplot to visualize balance/imbalance\n","# YOUR CODE HERE"],"metadata":{"id":"g-8bU9moco7l"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["If there is any imbalance in the dataset then a few techniques can be utilised (optional):\n","1. SMOTE\n","2. Cross Validation\n","3. Regularizing the model's parameters"],"metadata":{"id":"0N7tqroWP9iQ"}},{"cell_type":"markdown","source":["###Plot pairplot"],"metadata":{"id":"79pQoaQ3iOG7"}},{"cell_type":"markdown","source":["**Exercise 6: Visualize the relationships between the predictor variables and the target variable using a pairplot [0.5 Mark]**"],"metadata":{"id":"3Hfry_Fwr5nQ"}},{"cell_type":"markdown","source":["**Hint:** Use sns.pairplot"],"metadata":{"id":"aTBi6PLqsDbk"}},{"cell_type":"code","source":["# Visualize a pairplot with relevant features\n","# YOUR CODE HERE"],"metadata":{"_uuid":"a7355f1c5bf552fca19d132df33d7994516873f6","trusted":true,"id":"OO9RJlfrCEVp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Explore Correlation\n","\n","- Plotting the Heatmap"],"metadata":{"id":"UVKpOQqPuyew"}},{"cell_type":"markdown","source":["**Exercise 7: Visualize the correlation among IBM employee attrition numerical features using a heatmap [0.5 Mark]**"],"metadata":{"id":"aIMCrjr1sNJc"}},{"cell_type":"code","source":["# Visualize heatmap\n","# YOUR CODE HERE"],"metadata":{"id":"RC7eIV-P8rbX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Comment on the observations made with the pairplot and heatmap"],"metadata":{"id":"_FrUYzZWawAl"}},{"cell_type":"markdown","source":["### Preparing the test feature space\n","* Remove outliers if any\n","* Handle the categorical feature if required\n","* Other processing steps can also be followed."],"metadata":{"id":"oT9AhvtTQnKV"}},{"cell_type":"code","source":["# YOUR CODE HERE"],"metadata":{"id":"vfhan6UWQ8EX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Optional:\n","Use `Hyperopt`, a hyperparameter tuning technique to identify the best set of parameters.\n","\n","Refer to the Additional Notebook: CatBoost parameter tuning [CDS-B8 GDrive -> Module 3 -> Assignments -> July 27, 2024 -> Additional Notebook (ungraded) -> Addl_NB_Tuning_hyerparameters_using_Hyperopt]"],"metadata":{"id":"apS4f8aqWG71"}},{"cell_type":"markdown","source":["In the notebook, data processing is done separately for different models.\n","Considering the fact that different models may require data in different format and in turn different processes may be followed to process the data.\n","\n","If the processing steps followed for the models are same, data processing can also be done once."],"metadata":{"id":"j-ZPcVcn9w3U"}},{"cell_type":"markdown","source":["## Apply CatBoost\n","\n","Catboost was released in 2017 by Yandex, showing, by their benchmark to be faster in prediction, better in accuracy, and easier to use for categorical data across a series of GBDT tasks. Additional capabilities of catboost include plotting feature interactions and object (row) importance.\n","\n","[Here](https://catboost.ai/en/docs/) is the official documentation of CatBoost"],"metadata":{"_uuid":"63f0a5564f30228e710a3c1b7f7914bd986b93f1","id":"5ccGpKffCEVt"}},{"cell_type":"markdown","source":["### Data Processing for CatBoost"],"metadata":{"id":"7d7v3VlYQXGY"}},{"cell_type":"markdown","source":["**Exercise 8: Data processing for CatBoost [1 Mark]**\n","* **Copy the dataframe that was created after removing the outliers**\n","* **Handle the categorical features if required**\n","* **Create target column and feature space**"],"metadata":{"id":"45hA2ZB9tHGW"}},{"cell_type":"markdown","source":["**Hint:** Column containing the information on attrition will be the target column."],"metadata":{"id":"plxqVIWHt_9M"}},{"cell_type":"code","source":["# Copy the data\n","# YOUR CODE HERE"],"metadata":{"id":"V_mmH_ltZPvP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Target Column\n","# YOUR CODE HERE"],"metadata":{"id":"f-0M3uWuZs_B"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Feature Space\n","# YOUR CODE HERE"],"metadata":{"id":"icGflPlLaBre"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Model Definition"],"metadata":{"id":"s0Z0cbeS4BrT"}},{"cell_type":"markdown","source":["**Exercise 9: Define, train the model and display the results [2 Mark]**"],"metadata":{"id":"Bphb_wNwupwi"}},{"cell_type":"markdown","source":["**Hint:**\n","* Use CatBoostClassifier() to define the model with relevant parameters.\n","* Use `fit` to fit the data to the model. Refer [here](https://catboost.ai/en/docs/concepts/speed-up-training) to see some ways to speedup CatBoost training.\n","* Evaluate the model using roc_auc_score, accuracy_score, f1_score, predict methods or other relevant techniques."],"metadata":{"id":"K2e980Yyu3oJ"}},{"cell_type":"code","source":["# Create CatBoost model\n","# YOUR CODE HERE"],"metadata":{"id":"kIMPGCfMDIZR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Model training\n","# YOUR CODE HERE"],"metadata":{"id":"nkRYWmGfDMu-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Model performance"],"metadata":{"id":"stov-GDTGrOw"}},{"cell_type":"code","source":["# Model performance on all sets\n","# YOUR CODE HERE"],"metadata":{"id":"1k6sOOU-FNs7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Apply XGBoost\n","\n","XGBoost is a workhorse gradient boosted decision tree algorithm. Its been around since 2014 and has come to dominate the Kaggle and data science community. XGB introduced gradient boosting where new models are fit to the residuals of prior models and then added together, using a gradient descent algorithm to minimize the loss.\n","\n","Read [here](https://xgboost.readthedocs.io/en/stable/parameter.html) on XGBoost parameters.\n","\n","Refer [here](https://xgboost.readthedocs.io/en/stable/python/python_api.html#xgboost.XGBClassifier) for the official documentation of XGBoost classifier."],"metadata":{"id":"_hk4Kw5QGXCU"}},{"cell_type":"markdown","source":["### Data Processing for XGBoost\n"],"metadata":{"id":"3KbfDzqudx5H"}},{"cell_type":"markdown","source":["**Exercise 10: Data Processing for XGBoost [1 Mark]**\n","* **Copy the dataframe after the outliers were removed.**\n","* **Handle the categorical features if required**\n","* **Create target column and feature space**"],"metadata":{"id":"Yk6NedArvxbn"}},{"cell_type":"code","source":["# Copy dataframe\n","# YOUR CODE HERE"],"metadata":{"id":"wT2RVw4JTAGp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Hint:** Use pd.get_dummies"],"metadata":{"id":"jeTPMeNlwP2e"}},{"cell_type":"code","source":["# Handling categorical features\n","# YOUR CODE HERE"],"metadata":{"id":"QX1wnlPFWViw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Concat the dummy variables to actual dataframe and remove initial categorical columns\n","# YOUR CODE HERE"],"metadata":{"id":"f-K7vfixWup8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["When creating the dummy variables, the name of attrition column was changed, rename to 'attrition' again."],"metadata":{"id":"usRVCrd5wkC1"}},{"cell_type":"markdown","source":["**Hint:** Use .rename"],"metadata":{"id":"OnyrNF9Fw2eS"}},{"cell_type":"code","source":["# Rename target column\n","# YOUR CODE HERE"],"metadata":{"id":"sCkr7gvLXxLs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Feature Space\n","# YOUR CODE HERE\n","\n","# Targer label\n","# YOUR CODE HERE"],"metadata":{"id":"SA-WIpLAX3KH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Model Definition"],"metadata":{"id":"ccLyB9J04hDF"}},{"cell_type":"markdown","source":["**Exercise 11: Define, train the model and display the results [2 Mark]**"],"metadata":{"id":"JPinBk5NxRpt"}},{"cell_type":"markdown","source":["**Hint:**\n","* Use XGBClassifier() to define the model with relevant parameters.\n","* Use `fit` to fit the data to the model.\n","* Evaluate the model using roc_auc_score, accuracy_score, f1_score, predict methods or other relevant techniques."],"metadata":{"id":"-LFyiv0Mxcl-"}},{"cell_type":"code","source":["# Create XGBoost classifier model\n","# YOUR CODE HERE"],"metadata":{"id":"nxtvfYpzVxTc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Model training\n","# YOUR CODE HERE"],"metadata":{"id":"hrN85N3X_Sar"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Model Performance"],"metadata":{"id":"cA5ZK31mPox1"}},{"cell_type":"code","source":["# Model performance on all sets\n","# YOUR CODE HERE"],"metadata":{"id":"wQXg9FhcmwIw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Apply LightGBM (Optional)\n","\n","LightGBM is an open-source GBDT framework created by Microsoft as a fast and scalable alternative to XGB and GBM. By default LightGBM will train a Gradient Boosted Decision Tree (GBDT), but it also supports random forests, Dropouts meet Multiple Additive Regression Trees (DART), and Gradient Based One-Side Sampling (Goss).\n","\n","To know more about LightGBM parameters, refer [here](https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.LGBMClassifier.html#lightgbm.LGBMClassifier)."],"metadata":{"_uuid":"d1aa61b46b4cc4966124e75394f6f5a1e585f3cc","id":"8Iki__IJCEVs"}},{"cell_type":"markdown","source":["### Feature Engineering for LightGBM"],"metadata":{"id":"QGVwrT59tEx_"}},{"cell_type":"code","source":["## Following the same procedure as followed in XGBoost\n","\n","# Copy the dataframe\n","# YOUR CODE HERE\n","\n","# Handling categorical features\n","# YOUR CODE HERE\n","\n","# Concat the dummy variables to actual dataframe and remove initial categorical columns\n","# YOUR CODE HERE\n","\n","# Rename target column\n","# YOUR CODE HERE\n","\n","# Features Space\n","# YOUR CODE HERE\n","\n","# Target Label\n","# YOUR CODE HERE"],"metadata":{"id":"eYq9Z02Bs4-x"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Model Definition"],"metadata":{"id":"HNxN3-gU4ZWn"}},{"cell_type":"markdown","source":["**Hint:**\n","* Use LGBMClassifier() to define the model with relevant parameters.\n","* Use `fit` to fit the data to the model.\n","* Evaluate the model using roc_auc_score, accuracy_score, f1_score, predict methods or other relevant techniques."],"metadata":{"id":"lrZlE4IJydou"}},{"cell_type":"code","source":["# Create LightGBM classifier model\n","# YOUR CODE HERE"],"metadata":{"id":"4fWl23dHXHAP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Model training\n","# YOUR CODE HERE"],"metadata":{"id":"5FktD02ntN1T"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Model performance"],"metadata":{"id":"upM6hxP_SbPw"}},{"cell_type":"code","source":["# Model performance on all sets\n","# YOUR CODE HERE"],"metadata":{"id":"mmM2WvTGSd_l"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Results"],"metadata":{"_uuid":"33789095f30bba0c1ae0d9c5c78207ba4014800b","id":"18zLjk0qCEVu"}},{"cell_type":"markdown","source":["**Exercise 12: Create a dataframe of XGBoost results and CatBoost results and display them [0.5 Mark]**"],"metadata":{"id":"2eQwUXGgy78m"}},{"cell_type":"markdown","source":["**Hint:** Use pd.DataFrame"],"metadata":{"id":"nWQkWdRmzQ6n"}},{"cell_type":"code","source":["# Create a dataframe for computed metrics for different models\n","# YOUR CODE HERE"],"metadata":{"_uuid":"8c99bac7c8c6302c2d2fb6e00f1f17453d972265","trusted":true,"id":"qFGMmqS-CEVu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Reference reading:\n","1. https://machinelearningmastery.com/xgboost-for-imbalanced-classification/"],"metadata":{"id":"tWJ9p6CSfxAH"}},{"cell_type":"markdown","source":["## Kaggle Prediction"],"metadata":{"id":"Txq8oLEs4Op1"}},{"cell_type":"markdown","source":["Load data from Kaggle competition site"],"metadata":{"id":"7uHk3jvf4S46"}},{"cell_type":"code","source":["# From the given Kaggle competition link, load the dataset 'hr_employee_attrition_test.csv'\n","# YOUR CODE HERE"],"metadata":{"id":"Fciin_p26_jA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# From the dataset 'hr_employee_attrition_test.csv', drop columns ['id','employeenumber', 'employeecount', 'over18'] having single value\n","# YOUR CODE HERE"],"metadata":{"id":"pleyFrRf7Ds0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Handle categorical features\n","# YOUR CODE HERE"],"metadata":{"id":"fYvpXIaw7hQQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Concat the dummy variables to actual dataframe and remove initial categorical columns\n","# YOUR CODE HERE"],"metadata":{"id":"AnihyFFM7pbC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Predictions"],"metadata":{"id":"KfiThqH87vs1"}},{"cell_type":"code","source":["# Get the predictions using your already trained CatBoost classifier model achieved in Exercise 9\n","# YOUR CODE HERE"],"metadata":{"id":"hW-vkBcs74se"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Get the predictions using your already trained XGBoost classifier model achieved in Exercise 11\n","# YOUR CODE HERE"],"metadata":{"id":"u9nTocSC91-9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Get the predictions using your trained Microsoft LightGBM model (Optional)"],"metadata":{"id":"5kW1VMpW-20p"}},{"cell_type":"code","source":["# Get the predictions using your already trained Microsoft LightGBM classifier model\n","# achieved under the optional exercise 'Apply LightGBM (Optional)'\n","# YOUR CODE HERE"],"metadata":{"id":"vMHO0g9B-PtX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Save predictions to csv and submit under given Kaggle competiton link"],"metadata":{"id":"L4rzXFk-_lzk"}},{"cell_type":"code","source":["# YOUR CODE HERE"],"metadata":{"id":"F0zukSXl_wcP"},"execution_count":null,"outputs":[]}]}