{"cells":[{"cell_type":"markdown","metadata":{"id":"I1xuuUQdpC0r"},"source":["# Advanced Certification Program in Computational Data Science\n","## A Program by IISc and TalentSprint\n","### Additional Notebook (ungraded) on SHAP Values\n"]},{"cell_type":"markdown","metadata":{"id":"6FM0dpHA5Tss"},"source":["## Learning Objectives"]},{"cell_type":"markdown","metadata":{"id":"GsLv6_nh5YUG"},"source":["At the end of the experiment, you will be able to\n","\n","* Understand the concept of Shapley values.\n","* Implement SHAP for regression models and classification models\n","* Understand the insights derived from the SHAP implementation"]},{"cell_type":"code","source":["#@title Walkthrough Video\n","from IPython.display import HTML\n","HTML(\"\"\"<video width=\"420\" height=\"240\" controls>\n","<source src=\"https://cdn.exec.talentsprint.com/content/04_Aug_2022SHAP.mp4\">\n","</video>\"\"\")"],"metadata":{"cellView":"form","id":"OXZ1yamqNNmG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VBUrsbLd51SC"},"source":["### Introduction\n","\n","  * Machine learning models are usually thought of as a “black box.” A model takes some features as input and produces some predictions as output. The common questions after model training are:\n","    - How do different features affect the prediction results?\n","    - What are the top features that influence the prediction results?\n","    - Are the model performance metrics giving the full picture?\n","\n","* Model explainability therefore plays an important role in machine learning, as the insights are useful in:\n","    - Debugging\n","    - Informing feature engineering\n","    - Directing future data collection\n","    - Informing human decision-making\n","    - Building trust\n","\n","* To better understand or explain what is happening inside a machine learning model, we will use an open-source library called **SHAP.**"]},{"cell_type":"markdown","metadata":{"id":"0KaPV1na-T4L"},"source":["### SHAP"]},{"cell_type":"markdown","metadata":{"id":"eZPz2cjU-f-A"},"source":["The SHAP (SHapley Additive exPlanations) framework is an important advancement in the field of machine learning model interpretation. It was developed by Scott Lundberg and Su-In Lee, and combines several existing methods to create an intuitive, theoretically-sound approach to explain predictions for any model.\n","\n","  * SHAP builds model explanations by asking the same question for every prediction and feature: “How does prediction $i$ change when feature $j$ is removed from the model?” So-called SHAP values are the answers. They quantify the magnitude and direction (positive or negative) of a feature’s effect on a prediction.\n","\n","  * The Python software package [`shap`](https://github.com/slundberg/shap), developed by Scott Lundberg et al., provides utilities to calculate and plot SHAP values. The project’s main page demonstrates typical SHAP plots and provides links to example notebooks."]},{"cell_type":"markdown","metadata":{"id":"kzav2DlJY-K0"},"source":["For example, in the figure below, the features \"Age=65\", \"BP=180\" and \"BMI=40\" are contributing positively to give the output as 0.4 or they are moving it away from base value (the average of the prediction by the model), which is 0.1 in this case, because the shapley values of these features is positive.\n","\n","\n","![model interpretation](https://cdn.iisc.talentsprint.com/CDS/Images/Shap_model.png)\n","\n","In the same sense, feature \"SEX=F\" is contributing negatively to give the output 0.4 or it is decreasing the output which is evident from its negative shapley value. In turn it makes the output move towards the base value\n","\n","Hence SHAP helps to explain what was the contribution of each feature value in giving a particular output by the model."]},{"cell_type":"markdown","metadata":{"id":"kDoEIGVWCBZD"},"source":["To know more details about SHAP refer [here](https://christophm.github.io/interpretable-ml-book/shap.html)\n","\n","To understand the Math behind SHAP refer [here](https://cdn.extras.talentsprint.com/CDS/MiniProjects/SHAP%20Math%20explained.pdf)"]},{"cell_type":"markdown","metadata":{"id":"f66s-zQwH4le"},"source":["### Installing SHAP"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pbexIAyWCYP5"},"outputs":[],"source":["!pip install shap"]},{"cell_type":"markdown","metadata":{"id":"pTlX7l6pHb4B"},"source":["This notebook is divided into two sections:\n","* Regression\n","* Classification\n","\n","Implementation of SHAP has been discussed in detail both for regression and classification using different models and visualization techniques."]},{"cell_type":"markdown","metadata":{"id":"vfwcO08mA770"},"source":["# **Regression**"]},{"cell_type":"markdown","metadata":{"id":"S_eH2PGDG3QY"},"source":["To proceed to the official documentation of SHAP for Regression models, click [here](https://shap.readthedocs.io/en/latest/example_notebooks/tabular_examples/model_agnostic/Diabetes%20regression.html)"]},{"cell_type":"markdown","metadata":{"id":"Xhg4qRMRv2Hs"},"source":["### Regression on Diabetes dataset with Scikit-learn"]},{"cell_type":"markdown","metadata":{"id":"OAlp3mZCv5R2"},"source":["### Load data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iW1iDrQpCxNY"},"outputs":[],"source":["import warnings\n","import sklearn\n","from sklearn.model_selection import train_test_split\n","import numpy as np\n","import shap\n","import time\n","\n","X,y = shap.datasets.diabetes()\n","X_train,X_test,y_train,y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n","print(X_train.shape)\n","print(X_test.shape)\n","# rather than use the whole training set to estimate expected values, we summarize with\n","# a set of weighted kmeans, each weighted by the number of points they represent.\n","X_train_summary = shap.kmeans(X_train, 10)\n","\n","def print_accuracy(f):\n","    print(\"Root mean squared test error = {0}\".format(np.sqrt(np.mean((f(X_test) - y_test)**2))))\n","    time.sleep(0.5) # to let the print get out before any progress bars\n","\n","\n","#ignore warnings\n","warnings.filterwarnings('ignore')\n","shap.initjs()"]},{"cell_type":"markdown","metadata":{"id":"6ovm0fGav94m"},"source":["### Linear regression"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R0ZpJn2zvo4m"},"outputs":[],"source":["from sklearn import linear_model\n","lin_regr = linear_model.LinearRegression()\n","lin_regr.fit(X_train, y_train)\n","\n","print_accuracy(lin_regr.predict)"]},{"cell_type":"markdown","metadata":{"id":"FWNf8X2qwF1s"},"source":["### Explain a single prediction from the test set"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EflcfRIIwBXX"},"outputs":[],"source":["shap.initjs()\n","ex = shap.KernelExplainer(lin_regr.predict, X_train_summary)\n","shap_values = ex.shap_values(X_test.iloc[0,:])\n","shap.force_plot(ex.expected_value, shap_values, X_test.iloc[0,:])"]},{"cell_type":"markdown","metadata":{"id":"ViEzj0MTY-K6"},"source":["Each feature value is a force that either increases or decreases the prediction. The prediction starts from the baseline. The baseline for shapley values is the average of all predictions. In the plot, each Shapley value is an arrow that pushes to increase (positive value) or decrease (negative value) the prediction. These forces balance each other out at the actual prediction of the data instance.\n","\n","In blue, we have negative shapley values, it will decrease the value of prediction for this instance. While the shapley value in red represents everything that will increase the value of prediction for this instance."]},{"cell_type":"markdown","metadata":{"id":"GwRT1VLMY-K7"},"source":["Here the base value is 151, feature value \"bmi\" and \"bp\" making f(x)(prediction value = 238.47) move away from the base line which in turn makes its value to rise. The features values \"sex\" and \"s2\" are making it move in a negative direction or decreasing its value."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HXrrJ37QwKdq"},"outputs":[],"source":["shap.initjs()\n","shap_values = ex.shap_values(X_test)\n","shap.summary_plot(shap_values, X_test)"]},{"cell_type":"markdown","metadata":{"id":"6Iit3lAfY-K7"},"source":["This is a summary plot which combines feature importance with feature effects. Each point on the summary plot is a shapley value for a feature and an instance. The position on the y-axis is determined by the feature and on the x-axis by the shapley value. The color represents the value of the feature from low to high. This is a global interpretation of the effect of each value of every feature upon the respective predictions.\n","\n","\n","The shapley values are plotted on the x axis. The features are plotted on the y axis towards the left side. And for every feature value its tendency is plotted with dots.\n","\n","For eg:-\n","s4 has more values towards right side of the graph, this will make the predictions move in the positive directions or the value of predictions will increase because of the values of feature s4."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dWBSEv7-86N4"},"outputs":[],"source":["shap.dependence_plot(\"bmi\", shap_values, X_test)"]},{"cell_type":"markdown","metadata":{"id":"3KsUOu-4Y-K7"},"source":["Above plot demonstrates the behaviour of all the values of a single feature upon the output of the model.\n","To understand the effect, a single feature has on the model output, we can plot a SHAP value of that feature vs. the value of the feature for all instances in the dataset. Vertical dispersions at a single value show the effect of interaction with other features which are absent for this particular plot. It means that the interaction between \"bmi\" and other features is absent.\n","\n","Each dot represents a row of the data. The horizontal location is the actual value of that datapoint. The vertical location is demonstrating the effect of that feature value over the output of the model.\n","\n","The upward moving slope of bmi suggests that bmi has a direct and positive effect upon the target/output. The feature plotted towards the right is the one with which bmi has interacted the most.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VhNyJgIQ86Kn"},"outputs":[],"source":["shap.initjs()\n","shap.force_plot(ex.expected_value, shap_values, X_test)"]},{"cell_type":"markdown","metadata":{"id":"N6S9Qv4SY-K8"},"source":["Clustering Shapley Values:\n","You can cluster your data with the help of Shapley values. The goal of clustering is to find groups of similar instances.\n","SHAP clustering works by clustering the Shapley values of each instance. This means that you cluster instances by explanation similarity.\n","The plot consists of many force plots, each of which explains the prediction of an instance. We rotate the force plots vertically and place them side by side according to their clustering similarity.\n","\n","\n","The above plot describes the behaviour of output with respect to different features. The feature with which the user wants to see the interaction of the predicted variable can be set from the drop down menu given just above the plot.\n","\n","The color coding behaviour of the plot is same, red describing the ratio of the feature instances making the prediction rise and vise versa for blue.\n","\n","If cursor is scrolled over the plot, the instance values for different features will pop up, giving more insight about the datapoints for that particular prediction."]},{"cell_type":"markdown","metadata":{"id":"cYWAUfWW9yTv"},"source":["### Decision tree regressor"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QLFVe9UE86II"},"outputs":[],"source":["from sklearn import tree\n","dtree = tree.DecisionTreeRegressor(min_samples_split=20)\n","dtree.fit(X_train, y_train)\n","print_accuracy(dtree.predict)\n","\n","# explain all the predictions in the test set\n","ex = shap.TreeExplainer(dtree)\n","shap_values = ex.shap_values(X_test)\n","shap.summary_plot(shap_values, X_test)"]},{"cell_type":"markdown","metadata":{"id":"YHwV-JL-Y-K8"},"source":["On grounds of similar interpretation as above, it can be seen from the above plot that majority datapoints of the feature bmi are contributing positively in prediction and so on."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2pUUUGrc86Ff"},"outputs":[],"source":["shap.dependence_plot(\"bmi\", shap_values, X_test)"]},{"cell_type":"markdown","metadata":{"id":"2UytFqCUY-K9"},"source":["In contrary to above plots, this plot has a vertical spread that suggests the interaction of bmi with other features when it comes to it's effect upon feature s5."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K0nAduMB86DI"},"outputs":[],"source":["shap.initjs()\n","shap.force_plot(ex.expected_value, shap_values, X_test)"]},{"cell_type":"markdown","metadata":{"id":"9A66BrgA-HfZ"},"source":["### Random forest"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2XXgacqa86Ad"},"outputs":[],"source":["from sklearn.ensemble import RandomForestRegressor\n","rforest = RandomForestRegressor(n_estimators=1000, max_depth=None, min_samples_split=2, random_state=0)\n","rforest.fit(X_train, y_train)\n","print_accuracy(rforest.predict)\n","\n","# explain all the predictions in the test set\n","explainer = shap.TreeExplainer(rforest)\n","shap_values = explainer.shap_values(X_test)\n","shap.summary_plot(shap_values, X_test)"]},{"cell_type":"markdown","metadata":{"id":"TyLpUZloY-K9"},"source":["In the above plot it is clearly visible that majority datapoints of bmi have a positive effect on prediction."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eZ0dYZtH85-N"},"outputs":[],"source":["shap.dependence_plot(\"bmi\", shap_values, X_test)"]},{"cell_type":"markdown","metadata":{"id":"0ruIwpLSY-K-"},"source":["In the above plot it can be seen that there is non-uniform contribution of bmi in making an output. Moreover for the same value of bmi, for eg, between 0.000 and 0.025, there are many datapoints that have a vertical spread suggesting the effect of other features in making those predictions."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8cig8R5_857r"},"outputs":[],"source":["shap.initjs()\n","shap.force_plot(explainer.expected_value, shap_values, X_test)\n"]},{"cell_type":"markdown","metadata":{"id":"vQoGRbE0-7h5"},"source":["### Neural network"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N1s5Web6855K"},"outputs":[],"source":["from sklearn.neural_network import MLPRegressor\n","nn = MLPRegressor(solver='lbfgs', alpha=1e-1, hidden_layer_sizes=(5, 2), random_state=0)\n","nn.fit(X_train, y_train)\n","print_accuracy(nn.predict)\n","\n","# explain all the predictions in the test set\n","explainer = shap.KernelExplainer(nn.predict, X_train_summary)\n","shap_values = explainer.shap_values(X_test)\n","shap.summary_plot(shap_values, X_test)"]},{"cell_type":"markdown","metadata":{"id":"wFUPC067Y-K-"},"source":["The summary plot combines feature importance with feature effects. Each point on the summary plot is a Shapley value for a feature and an instance. The position on the y-axis is determined by the feature and on the x-axis by the Shapley value. The color represents the value of the feature from low to high. Overlapping points are jittered in y-axis direction, so we get a sense of the distribution of the Shapley values per feature. The features are ordered according to their importance."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RVxi7EXd852n"},"outputs":[],"source":["shap.dependence_plot(\"bmi\", shap_values, X_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"L4636G5Y850F"},"outputs":[],"source":["shap.initjs()\n","shap.force_plot(explainer.expected_value, shap_values, X_test)"]},{"cell_type":"markdown","metadata":{"id":"SyJmS6EnBAkF"},"source":["# **Classification**"]},{"cell_type":"markdown","metadata":{"id":"oLEnQTo0HNKt"},"source":["To proceed to the official documentation of SHAP upon classification click [here](https://shap.readthedocs.io/en/latest/example_notebooks/tabular_examples/model_agnostic/Census%20income%20classification%20with%20scikit-learn.html)"]},{"cell_type":"markdown","metadata":{"id":"llUeLQT8BHef"},"source":["### Census income classification with scikit-learn\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2bjRUl4y-sfw"},"outputs":[],"source":["import sklearn\n","import shap"]},{"cell_type":"markdown","metadata":{"id":"qRMblxy9BMX6"},"source":["### Load the census data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OLOeRxIG-scW"},"outputs":[],"source":["X,y = shap.datasets.adult()\n","X[\"Occupation\"] *= 1000 # to show the impact of feature scale on KNN predictions\n","X_display,y_display = shap.datasets.adult(display=True)\n","X_train, X_valid, y_train, y_valid = sklearn.model_selection.train_test_split(X, y, test_size=0.2, random_state=7)"]},{"cell_type":"markdown","metadata":{"id":"c67oCpGCBViM"},"source":["### Train a k-nearest neighbors classifier\n","\n"]},{"cell_type":"markdown","metadata":{"id":"mlSx0D7KBaGx"},"source":["Here we just train directly on the data, without any normalizations.\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"L0ThSYIr-sZu"},"outputs":[],"source":["knn = sklearn.neighbors.KNeighborsClassifier()\n","knn.fit(X_train, y_train)"]},{"cell_type":"markdown","metadata":{"id":"MGJ6Pv76Bx_M"},"source":["### Explain predictions"]},{"cell_type":"markdown","metadata":{"id":"dBgK5v90B0vF"},"source":["Normally we would use a logit link function to allow the additive feature inputs to better map to the model’s probabilistic output space, but KNNs can produce infinite log odds ratios so we don’t for this example.\n","\n","It is important to note that Occupation is the dominant feature in the 1000 predictions we explain. This is because it has larger variations in value than the other features and so it impacts the k-nearest neighbors calculations more."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QPL4cAMD-sXg"},"outputs":[],"source":["f = lambda x: knn.predict_proba(x)[:,1]\n","med = X_train.median().values.reshape((1,X_train.shape[1]))\n","\n","explainer = shap.Explainer(f, med)\n","shap_values = explainer(X_valid.iloc[0:1000,:])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tmrfpBiS-sUr"},"outputs":[],"source":["shap.plots.waterfall(shap_values[1])"]},{"cell_type":"markdown","metadata":{"id":"RCKwoBYkDkzz"},"source":["A summary beeswarm plot is an even better way to see the relative impact of all features over the entire dataset. Features are sorted by the sum of their SHAP value magnitudes across all samples."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8Zu6erCw-sQA"},"outputs":[],"source":["shap.plots.beeswarm(shap_values)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fmGFDxeVB645"},"outputs":[],"source":["shap.plots.heatmap(shap_values)"]},{"cell_type":"markdown","metadata":{"id":"-CP3chbNY-LC"},"source":["A heatmap plot provides another global view of the model’s behavior, this time with a focus on population subgroups."]},{"cell_type":"markdown","metadata":{"id":"3sIg08i0Y-LC"},"source":["Here plotted horizontally are instances and color bars for them depicts what is the general behaviour of the instance sub-group for that particular feature over the output or the prediction of the model for a particular sub-group of instances.\n","\n","It can be clearly seen that in the instances, there are sub-groups at 800 for occupation feature. The general color coding is red which depicts that they have a positive effect upon the prediction. This can also be seen by the rising curve for the line f(x) towards the top."]},{"cell_type":"markdown","metadata":{"id":"HTqd4jl0D0zh"},"source":["### Normalize the data before training the model"]},{"cell_type":"markdown","metadata":{"id":"rYrFClh2D4bb"},"source":["Here we retrain a KNN model on standardized data."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ciOhbGaaB62i"},"outputs":[],"source":["# normalize data\n","dtypes = list(zip(X.dtypes.index, map(str, X.dtypes)))\n","X_train_norm = X_train.copy()\n","X_valid_norm = X_valid.copy()\n","for k,dtype in dtypes:\n","    m = X_train[k].mean()\n","    s = X_train[k].std()\n","    X_train_norm[k] -= m\n","    X_train_norm[k] /= s\n","\n","    X_valid_norm[k] -= m\n","    X_valid_norm[k] /= s"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aXanx3RVB605"},"outputs":[],"source":["knn_norm = sklearn.neighbors.KNeighborsClassifier()\n","knn_norm.fit(X_train_norm, y_train)"]},{"cell_type":"markdown","metadata":{"id":"RHG3tnAHEB8Y"},"source":["### Explain predictions"]},{"cell_type":"markdown","metadata":{"id":"xxY5ZfYcEH3H"},"source":["When we explain predictions from the new KNN model we find that Occupation is no longer the dominant feature, but instead more predictive features, such as marital status, drive most predictions. This is simple example of how explaining why your model is making it’s predicitons can uncover problems in the training process."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XrL8SdWVB6sk"},"outputs":[],"source":["f = lambda x: knn_norm.predict_proba(x)[:,1]\n","med = X_train_norm.median().values.reshape((1,X_train_norm.shape[1]))\n","\n","explainer = shap.Explainer(f, med)\n","\n","shap_values_norm = explainer(X_valid_norm.iloc[0:1000,:])"]},{"cell_type":"markdown","metadata":{"id":"L6qxITb0GJeR"},"source":["With a summary plot with see marital status is the most important on average, but other features (such as captial gain) can have more impact on a particular individual."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o1vK5fu7B6pu"},"outputs":[],"source":["shap.summary_plot(shap_values_norm, X_valid.iloc[0:1000,:])"]},{"cell_type":"markdown","metadata":{"id":"JDt-sDNlGRTO"},"source":["A dependence scatter plot shows how the number of years of education increases the chance of making over 50K annually."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DYI5nQTWB6nh"},"outputs":[],"source":["shap.plots.scatter(shap_values_norm[:,\"Education-Num\"])"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"}},"nbformat":4,"nbformat_minor":0}