{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "another-optimum",
      "metadata": {
        "id": "another-optimum"
      },
      "source": [
        "# Advanced Certification Program in Computational Data Science\n",
        "\n",
        "##  A program by IISc and TalentSprint\n",
        "\n",
        "### Mini Project Notebook: Image Classification using Multi Layer Perceptron"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "maritime-miami",
      "metadata": {
        "id": "maritime-miami"
      },
      "source": [
        "## Learning Objectives"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "nljJR6CwfZN_",
      "metadata": {
        "id": "nljJR6CwfZN_"
      },
      "source": [
        "At the end of the experiment, you will be able to :\n",
        "\n",
        "* load and extract features of images\n",
        "\n",
        "* implement the Multi-Layer perceptron to classify images\n",
        "\n",
        "* implement simple neural network from keras"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "29152de7",
      "metadata": {
        "id": "29152de7"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "Traffic sign recognition is a challenging, real-world problem relevant for AI based transportation systems. Traffic signs show a wide range of variations between classes in terms of color, shape, and the presence of pictograms or text. However, there exist subsets of\n",
        "classes (e.g., speed limit signs) that are very similar to each other. Further, the classifier\n",
        "has to be robust against large variations in visual appearances due to changes in illumination, partial\n",
        "occlusions, rotations, weather conditions etc. Using a comprehensive traffic sign detection dataset, here we will perform classification of traffic signs, train and evaluate the different models and compare to the performance of MLPs."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "58facc94",
      "metadata": {
        "id": "58facc94"
      },
      "source": [
        "![img](https://paperswithcode.com/media/datasets/GTSRB-0000000633-9ce3c5f6_Dki5Rsf.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "surprising-uruguay",
      "metadata": {
        "id": "surprising-uruguay"
      },
      "source": [
        "## Dataset\n",
        "\n",
        "The data for this mini-project is from the German Traffic Sign Detection Benchmark [GTSDB](https://benchmark.ini.rub.de/gtsdb_dataset.html). This archive contains the training set used during the IJCNN 2013 competition. \n",
        "\n",
        "The German Traffic Sign Detection Benchmark is a single-image detection assessment for researchers with interest in the field of computer vision, pattern recognition and image-based driver assistance. It is introduced on the IEEE International Joint Conference on Neural Networks 2013. \n",
        "\n",
        "It features ...\n",
        "\n",
        "* The main archive FullIJCNN2013.zip includes the images (1360 x 800 pixels) in PPM format, the image sections containing only the traffic signs\n",
        "* A file in CSV format with the ground truth\n",
        "* A ReadMe.txt with more details.\n",
        "\n",
        "Note that we will be using the images inside the image sections subfolders, containing only the traffic signs."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ih-oasWmdZul",
      "metadata": {
        "id": "ih-oasWmdZul"
      },
      "source": [
        "## Problem Statement"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "qfWGmjNHdZul",
      "metadata": {
        "id": "qfWGmjNHdZul"
      },
      "source": [
        "To build and improve upon a machine learning model for the classification of images and achieve a high accuracy final model."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "operating-latter",
      "metadata": {
        "id": "operating-latter"
      },
      "source": [
        "## Grading = 10 Points"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "812a816f",
      "metadata": {
        "cellView": "form",
        "id": "812a816f"
      },
      "outputs": [],
      "source": [
        "# @title Download the data\n",
        "# !wget -qq https://sid.erda.dk/public/archives/ff17dc924eba88d5d01a807357d6614c/FullIJCNN2013.zip\n",
        "# !unzip -qq FullIJCNN2013.zip\n",
        "\n",
        "from utility import download_and_unzip\n",
        "\n",
        "download_and_unzip(\n",
        "    filename=\"FullIJCNN2013.zip\",\n",
        "    url=\"https://sid.erda.dk/public/archives/ff17dc924eba88d5d01a807357d6614c/FullIJCNN2013.zip\",\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "abstract-stocks",
      "metadata": {
        "id": "abstract-stocks"
      },
      "source": [
        "### Import Required packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "advisory-knowing",
      "metadata": {
        "id": "advisory-knowing"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from skimage.io import imread, imshow\n",
        "from sklearn import preprocessing\n",
        "import os, glob\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Keras\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, BatchNormalization\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "gp4bF_GJdZuo",
      "metadata": {
        "id": "gp4bF_GJdZuo"
      },
      "source": [
        "### Data Loading and Feature Extraction (2 points)\n",
        "\n",
        "#### Get the features and labels of data\n",
        "\n",
        "* Extract the features of the images within image sections only (do not use images located outside these folders)\n",
        "* Extract labels of the images\n",
        "* Resize the images to (30, 30) and convert to numpy 1-D array\n",
        "\n",
        "   Hint: [Link](https://machinelearningmastery.com/how-to-load-and-manipulate-images-for-deep-learning-in-python-with-pil-pillow/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc5c2362",
      "metadata": {
        "id": "fc5c2362"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "NUY3yNrdaABY",
      "metadata": {
        "id": "NUY3yNrdaABY"
      },
      "source": [
        "### Data Exploration and Preprocessing ( 2 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9ca63666",
      "metadata": {
        "id": "9ca63666"
      },
      "source": [
        "#### Plot the sample image of each class\n",
        "\n",
        "Hint: plt.subplot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c414e14e",
      "metadata": {
        "id": "c414e14e"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8a2rqCM-sIbY",
      "metadata": {
        "id": "8a2rqCM-sIbY"
      },
      "source": [
        "#### Plot the distribution of Classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "nwWKGQMFsIDP",
      "metadata": {
        "id": "nwWKGQMFsIDP"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "37b23a0b",
      "metadata": {
        "id": "37b23a0b"
      },
      "source": [
        "#### Normalize the features\n",
        "\n",
        "For most image data, the pixel values are integers with values between 0 and 255.\n",
        "\n",
        "Neural networks process inputs using small weight values, and inputs with large integer values can disrupt or slow down the learning process. As such it is good practice to normalize the pixel values.\n",
        "\n",
        "Hint: sklearn.preprocessing.normalize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82239736",
      "metadata": {
        "id": "82239736"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "28ea9c3a",
      "metadata": {
        "id": "28ea9c3a"
      },
      "source": [
        "### Train the MLP classifier on features (1 point)\n",
        "\n",
        "* Split the data into train and test\n",
        "\n",
        "* Train the MLP classifier with different parameters\n",
        "\n",
        "* Get the accuracy score and performance metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f952950",
      "metadata": {
        "id": "7f952950"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dfe1e294",
      "metadata": {
        "id": "dfe1e294"
      },
      "source": [
        "### Tune the hyper-parameters (2 points)\n",
        "\n",
        "* Use the GridSearchCV or RandomizedSearchCV and select best parameters\n",
        "\n",
        "  Hint: [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html), [RandomizedSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html)\n",
        "\n",
        "  (or)\n",
        "* Manually change and find the best parameters\n",
        "\n",
        "To know about all the parameters, click [here](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f29ce38e",
      "metadata": {
        "id": "f29ce38e"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "911d0a39",
      "metadata": {
        "id": "911d0a39"
      },
      "source": [
        "#### Try the different algorithms and compare the results with MLP classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08b0c234",
      "metadata": {
        "id": "08b0c234"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af9cd34e",
      "metadata": {
        "id": "af9cd34e"
      },
      "source": [
        "### Implement simple Neural Networks using keras (3 points)\n",
        "\n",
        "* Define the keras model and initialize the layers\n",
        "  - Ensure the input layer has the right number of input features. This can be specified when creating the first layer with the input_dim argument.\n",
        "* Compile the model\n",
        "  - Specify the loss function (to evaluate a set of weights), the optimizer (is used to search through different weights for the network) and any optional metrics to collect and report during training.\n",
        "* Fit and Evaluate the model\n",
        "  - Fit the data by specifying epochs and evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fcf8d025",
      "metadata": {
        "id": "fcf8d025"
      },
      "outputs": [],
      "source": [
        "print(tf.__version__)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ecbe0db",
      "metadata": {
        "id": "1ecbe0db"
      },
      "outputs": [],
      "source": [
        "# Step 1 - Build the architecture\n",
        "# YOUR CODE HERE\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4c7bc66",
      "metadata": {
        "id": "d4c7bc66"
      },
      "outputs": [],
      "source": [
        "# Step 2 - Compile the model\n",
        "# YOUR CODE HERE\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27Pltot4FsiG",
      "metadata": {
        "id": "27Pltot4FsiG"
      },
      "outputs": [],
      "source": [
        "# Step 3 - Fit and Evaluate the model\n",
        "# YOUR CODE HERE\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cSUDO2lLmQJO",
      "metadata": {
        "id": "cSUDO2lLmQJO"
      },
      "source": [
        "#### Try the same parameters used for MLP Classifier and build the keras model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1zNp5w4bvFz9",
      "metadata": {
        "id": "1zNp5w4bvFz9"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "IAHzeVx_tImO",
      "metadata": {
        "id": "IAHzeVx_tImO"
      },
      "source": [
        "#### Experiment using Dropout, Regularization and Batch Normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "w34gbejXvLUs",
      "metadata": {
        "id": "w34gbejXvLUs"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "MhWaGRRfs7tv",
      "metadata": {
        "id": "MhWaGRRfs7tv"
      },
      "source": [
        "### Report Analysis\n",
        "\n",
        "* According to the confusion matrix, for which sign were the maximum misclassifications observed? Comment on the misclassification, owing to similar appearing traffic signs, if any. \n",
        "* Comment on the performance of the MLP Classifier\n",
        "* Discuss the optimal number of layers, activation functions, optimizers etc. that yielded the best accuracy\n",
        "* Report on training time vs convergence"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d4978243",
      "metadata": {
        "id": "d4978243"
      },
      "source": [
        "Reference: J. Stallkamp, M. Schlipsing, J. Salmen, and C. Igel. The German Traffic Sign Recognition Benchmark: A multi-class classification competition. In Proceedings of the IEEE International Joint Conference on Neural Networks, pages 1453–1460. 2011."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
