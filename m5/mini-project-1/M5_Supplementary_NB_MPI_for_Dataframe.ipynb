{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "heated-queens",
   "metadata": {
    "id": "heated-queens"
   },
   "source": [
    "# Advanced Certification Program in Computational Data Science\n",
    "## A program by IISc and TalentSprint\n",
    "### Supplementary Notebook: Implementation of send and receive operation on a dataset using MPI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "military-proportion",
   "metadata": {
    "id": "military-proportion"
   },
   "source": [
    "## Learning Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "durable-grounds",
   "metadata": {
    "id": "durable-grounds"
   },
   "source": [
    "At the end of the mini-project, you will be able to :\n",
    "\n",
    "* implement the collective communication operations like scatter, gather, broadcast on a dataset using MPI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "growing-queens",
   "metadata": {
    "id": "growing-queens"
   },
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "raised-connection",
   "metadata": {
    "id": "raised-connection"
   },
   "source": [
    "Here, we will be using the “Iris dataset”.The Iris dataset contains 50 samples of 3 different species of iris (150 samples total).\n",
    "\n",
    "The columns in this dataset are:\n",
    "\n",
    "- SepalLength (cm)\n",
    "- SepalWidth (cm)\n",
    "- PetalLength (cm)\n",
    "- PetalWidth (cm)\n",
    "- Species"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "global-savings",
   "metadata": {
    "id": "global-savings"
   },
   "source": [
    "**Note:** We will be using the mpi4py Python package for MPI based code implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "green-deviation",
   "metadata": {
    "id": "green-deviation"
   },
   "source": [
    "**Run the below code to install mpi4py package**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "designing-marketing",
   "metadata": {
    "id": "designing-marketing",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install mpi4py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedicated-thong",
   "metadata": {
    "id": "dedicated-thong"
   },
   "source": [
    "#### Importing Necessary Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "reported-acrobat",
   "metadata": {
    "id": "reported-acrobat",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Importing pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Importing Numpy\n",
    "import numpy as np\n",
    "\n",
    "# Importing MPI from mpi4py package\n",
    "from mpi4py import MPI\n",
    "\n",
    "# Importing sqrt function from the Math\n",
    "from math import sqrt\n",
    "\n",
    "# Importing Decimal, ROUND_HALF_UP functions from the decimal package\n",
    "from decimal import Decimal, ROUND_HALF_UP\n",
    "import time\n",
    "from sklearn import datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "universal-jonathan",
   "metadata": {
    "cellView": "form",
    "id": "universal-jonathan",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset downloaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# @title Downloading the data\n",
    "iris = datasets.load_iris()\n",
    "dataset = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "dataset[\"species\"] = iris.target\n",
    "dataset[\"species\"] = dataset[\"species\"].apply(lambda x: iris.target_names[x])\n",
    "dataset.to_csv(\"iris_dataset.csv\", index=False)\n",
    "print(\"Dataset downloaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "early-peace",
   "metadata": {
    "id": "early-peace"
   },
   "source": [
    "### Load data\n",
    "\n",
    "Write a function that takes the filename as input and loads the data in a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "differential-vacation",
   "metadata": {
    "id": "differential-vacation",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "sepal length (cm)",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "sepal width (cm)",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "petal length (cm)",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "petal width (cm)",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "species",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "891c1481-3fba-41bd-8e4c-947de0d3555a",
       "rows": [
        [
         "0",
         "5.1",
         "3.5",
         "1.4",
         "0.2",
         "setosa"
        ],
        [
         "1",
         "4.9",
         "3.0",
         "1.4",
         "0.2",
         "setosa"
        ],
        [
         "2",
         "4.7",
         "3.2",
         "1.3",
         "0.2",
         "setosa"
        ],
        [
         "3",
         "4.6",
         "3.1",
         "1.5",
         "0.2",
         "setosa"
        ],
        [
         "4",
         "5.0",
         "3.6",
         "1.4",
         "0.2",
         "setosa"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "3                4.6               3.1                1.5               0.2   \n",
       "4                5.0               3.6                1.4               0.2   \n",
       "\n",
       "  species  \n",
       "0  setosa  \n",
       "1  setosa  \n",
       "2  setosa  \n",
       "3  setosa  \n",
       "4  setosa  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FILENAME = \"/content/iris_dataset.csv\"  # Storing File path\n",
    "FILENAME = \"iris_dataset.csv\"  # Storing File path\n",
    "\n",
    "\n",
    "# Defining a function to load the data\n",
    "def loadData(filename):\n",
    "    # Loading the dataset with column names as\n",
    "    data = pd.read_csv(filename)\n",
    "    # Returning the dataframe\n",
    "    return data\n",
    "\n",
    "\n",
    "# Calling the function loadData and storing the dataframe in a variable named df\n",
    "df = loadData(FILENAME)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bi0E5wjVUf4Y",
   "metadata": {
    "id": "bi0E5wjVUf4Y"
   },
   "source": [
    "### Point-to-point Blocking Communication"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3YpLjFRGWzlP",
   "metadata": {
    "id": "3YpLjFRGWzlP"
   },
   "source": [
    "**Passing the entire Dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "keiEqxNFSEwY",
   "metadata": {
    "id": "keiEqxNFSEwY"
   },
   "outputs": [],
   "source": [
    "%%writefile passing_dataframe.py\n",
    "from mpi4py import MPI # Importing mpi4py package from MPI module\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Defining a function\n",
    "\n",
    "FILENAME = \"/content/iris_dataset.csv\" # Storing File path\n",
    "# Defining a function to load the data\n",
    "def loadData(filename):\n",
    "    # Loading the dataset with column names as\n",
    "    data = pd.read_csv(filename)\n",
    "    # Returning the dataframe\n",
    "    return data\n",
    "# Calling the function loadData and storing the dataframe in a variable named df\n",
    "df = loadData(FILENAME)\n",
    "\n",
    "def main():\n",
    "    # Creating a communicator\n",
    "    comm = MPI.COMM_WORLD\n",
    "    # number of the process running the code\n",
    "    rank = comm.Get_rank()\n",
    "    # total number of processes running\n",
    "    size = comm.Get_size()\n",
    "    # master process\n",
    "    if rank == 0:\n",
    "        # Generate a dictionary with arbitrary data in it\n",
    "        data = df\n",
    "        # master process sends data to worker processes by\n",
    "        # going through the ranks of all worker processes\n",
    "        for i in range(1, size):\n",
    "            # Sending data\n",
    "            comm.send(data, dest=i, tag=i)\n",
    "            # Displaying the results\n",
    "            print('Process {} sent data:'.format(rank), data)\n",
    "    # worker processes\n",
    "    else:\n",
    "        # each worker process receives data from master process\n",
    "        data = comm.recv(source=0, tag=rank)\n",
    "        # Displaying the results\n",
    "        print('Process {} received data:'.format(rank), data)\n",
    "# Calling the function\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pFg8vnR8TPpO",
   "metadata": {
    "id": "pFg8vnR8TPpO"
   },
   "outputs": [],
   "source": [
    "!mpirun --allow-run-as-root -np 4 python passing_dataframe.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qD2RmEKDXLb_",
   "metadata": {
    "id": "qD2RmEKDXLb_"
   },
   "source": [
    "### Collective Communication\n",
    "\n",
    "In MPI for Python, the `Comm.Bcast`, `Comm.Scatter`, `Comm.Gather`, `Comm.Allgather`, `Comm.Alltoall` methods provide support for collective communications of memory buffers. The lower-case variants `Comm.bcast`, `Comm.scatter`, `Comm.gather`, `Comm.allgather` and `Comm.alltoall` can communicate general Python objects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5__NCyrAZZo0",
   "metadata": {
    "id": "5__NCyrAZZo0"
   },
   "source": [
    "#### **Broadcasting the entire Dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "THdnsUfeZecF",
   "metadata": {
    "id": "THdnsUfeZecF"
   },
   "outputs": [],
   "source": [
    "%%writefile BroadcastingDataframe.py\n",
    "from mpi4py import MPI # Importing mpi4py package from MPI module\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "FILENAME = \"/content/iris_dataset.csv\" # Storing File path\n",
    "# Defining a function to load the data\n",
    "def loadData(filename):\n",
    "    # Loading the dataset with column names as\n",
    "    data = pd.read_csv(filename)\n",
    "    # Returning the dataframe\n",
    "    return data\n",
    "# Calling the function loadData and storing the dataframe in a variable named df\n",
    "df = loadData(FILENAME)\n",
    "\n",
    "# Defining a function\n",
    "def main():\n",
    "    comm = MPI.COMM_WORLD\n",
    "    id = comm.Get_rank()            #number of the process running the code\n",
    "    numProcesses = comm.Get_size()  #total number of processes running\n",
    "    if id == 0:\n",
    "        # Generate a dictionary with arbitrary data in it\n",
    "        data = df\n",
    "    else:\n",
    "        # start with empty data\n",
    "        data = None\n",
    "    # Broadcasting the data\n",
    "    data = comm.bcast(data, root=0)\n",
    "    # Printing the data along with the id number\n",
    "    print('Rank: ', id,', received data: ' , data, '\\n')\n",
    "\n",
    "# Calling a function\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ilxQQHXsZeZM",
   "metadata": {
    "id": "ilxQQHXsZeZM"
   },
   "outputs": [],
   "source": [
    "! mpirun --allow-run-as-root -np 4 python BroadcastingDataframe.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "JfvkwghAa3Zu",
   "metadata": {
    "id": "JfvkwghAa3Zu"
   },
   "source": [
    "#### **Scatter Operation on the Dataframe**\n",
    "\n",
    "- Create a function to divide the dataframe equally among different processes.\n",
    "- Perform scatter operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TmLefFkIbT5u",
   "metadata": {
    "id": "TmLefFkIbT5u"
   },
   "outputs": [],
   "source": [
    "%%writefile ScatteringDataframe.py\n",
    "from mpi4py import MPI # Importing mpi4py package from MPI module\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from decimal import Decimal, ROUND_HALF_UP # Importing Decimal, ROUND_HALF_UP functions from the decimal package\n",
    "\n",
    "FILENAME = \"/content/iris_dataset.csv\" # Storing File path\n",
    "# Defining a function to load the data\n",
    "def loadData(filename):\n",
    "    # Loading the dataset with column names as\n",
    "    data = pd.read_csv(filename)\n",
    "    # Returning the dataframe\n",
    "    return data\n",
    "# Calling the function loadData and storing the dataframe in a variable named df\n",
    "df = loadData(FILENAME)\n",
    "\n",
    "def dividing_data(dataset, size_of_workers):\n",
    "    #Divide the data among the workers\n",
    "    slice_for_each_worker = int(Decimal(dataset.shape[0]/size_of_workers).quantize(Decimal('1.'), rounding = ROUND_HALF_UP))\n",
    "    print('Slice of data for each worker: {}'.format(slice_for_each_worker))\n",
    "    data_for_worker = []\n",
    "    for i in range(0, size_of_workers):\n",
    "        if i < size_of_workers - 1:\n",
    "            data_for_worker.append(dataset[slice_for_each_worker*i:slice_for_each_worker*(i+1)])\n",
    "        else:\n",
    "            data_for_worker.append(dataset[slice_for_each_worker*i:])\n",
    "    return data_for_worker\n",
    "\n",
    "# Defining a function\n",
    "def main():\n",
    "    # communicator\n",
    "    comm = MPI.COMM_WORLD\n",
    "    rank = comm.Get_rank()   # number of the process running the code\n",
    "    size = comm.Get_size()   # total number of processes running\n",
    "    data = None # Starting with an empty  data\n",
    "    if rank == 0:\n",
    "        # Creating a Numpy array.\n",
    "        data = dividing_data(df, size)\n",
    "    # scatter operation\n",
    "    received_data = comm.scatter(data, root=0)\n",
    "    # Displaying the result\n",
    "    print('Rank: ', rank, ', recvbuf: ', received_data)\n",
    "\n",
    "# Calling the main function\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "HiHTRijCbT23",
   "metadata": {
    "id": "HiHTRijCbT23"
   },
   "outputs": [],
   "source": [
    "! mpirun --allow-run-as-root -np 4 python ScatteringDataframe.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ybOD9TLilB67",
   "metadata": {
    "id": "ybOD9TLilB67"
   },
   "source": [
    "#### **Gather Operation on the Dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "JNgsoqyBlVLC",
   "metadata": {
    "id": "JNgsoqyBlVLC"
   },
   "outputs": [],
   "source": [
    "%%writefile GatherringDataframe.py\n",
    "from mpi4py import MPI # Importing mpi4py package from MPI module\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from decimal import Decimal, ROUND_HALF_UP # Importing Decimal, ROUND_HALF_UP functions from the decimal package\n",
    "\n",
    "FILENAME = \"/content/iris_dataset.csv\" # Storing File path\n",
    "# Defining a function to load the data\n",
    "def loadData(filename):\n",
    "    # Loading the dataset with column names as\n",
    "    data = pd.read_csv(filename)\n",
    "    # Returning the dataframe\n",
    "    return data\n",
    "# Calling the function loadData and storing the dataframe in a variable named df\n",
    "df = loadData(FILENAME)\n",
    "\n",
    "# Defining a function\n",
    "def main():\n",
    "    # communicator\n",
    "    comm = MPI.COMM_WORLD\n",
    "    rank = comm.Get_rank()   # number of the process running the code\n",
    "    size = comm.Get_size()   # total number of processes running\n",
    "    slice_for_each_worker = int(Decimal(df.shape[0]/size).quantize(Decimal('1.'), rounding = ROUND_HALF_UP))   # Number of elements in a array for each rank\n",
    "    # Creating a sender buffer array\n",
    "    if rank < size-1:\n",
    "        sendbuf = df[slice_for_each_worker*rank:slice_for_each_worker*(rank+1)]\n",
    "    else:\n",
    "        sendbuf = df[slice_for_each_worker*rank:]\n",
    "    # Printing the result\n",
    "    print('Rank: ',rank, ', sendbuf: ', sendbuf)\n",
    "    recvbuf = None\n",
    "    # Gathering the Information\n",
    "    recvbuf = comm.gather(sendbuf, root = 0)\n",
    "    # Display the result\n",
    "    if rank == 0:\n",
    "        print('Rank: ',rank, ', recvbuf received: ', recvbuf)\n",
    "\n",
    "# Calling a function\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wChauhLFlYZu",
   "metadata": {
    "id": "wChauhLFlYZu"
   },
   "outputs": [],
   "source": [
    "! mpirun --allow-run-as-root -np 4 python GatherringDataframe.py\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
