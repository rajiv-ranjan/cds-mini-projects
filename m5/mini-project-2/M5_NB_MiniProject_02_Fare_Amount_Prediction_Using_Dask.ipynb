{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hawaiian-astronomy"
   },
   "source": [
    "# Advanced Certification Program in Computational Data Science\n",
    "## A program by IISc and TalentSprint\n",
    "### Mini Project: Implementation of Linear Regression on a Large Dataset Using Dask Library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "latin-seventh"
   },
   "source": [
    "## Learning Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "civil-joyce"
   },
   "source": [
    "At the end of the mini-project, you will be able to :\n",
    "\n",
    "- understand how dask handles large dataset over pandas dataframe\n",
    "- perform exploratory data analysis on a large dataset (2 Million rows) using dask\n",
    "- implement linear regression model using dask library and make predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cm1iYi7ZD7Yq"
   },
   "source": [
    "## Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wlU7vlOfD7uk"
   },
   "source": [
    " Predict the taxi fare amount in New York city using Dask-ML."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tGHv4isOD72Y"
   },
   "source": [
    "## Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bprA1vC_Fgjc"
   },
   "source": [
    "### Dask\n",
    "[Dask](https://dask.pydata.org/en/latest/) is an open source project that gives abstractions over NumPy Arrays, Pandas Dataframes and regular lists, allowing you to run operations on them in parallel, using multicore processing.\n",
    "\n",
    "We can summarize the basics of Dask as follows:\n",
    "\n",
    "* processes data that doesn’t fit into memory by breaking it into blocks and specifying task chains\n",
    "\n",
    "* parallelizes execution of tasks across cores and even nodes of a cluster\n",
    "\n",
    "* moves computation to the data rather than the other way around, to minimize communication overhead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5YrOzD0RL5fc"
   },
   "source": [
    "### Dataset\n",
    "\n",
    "The dataset is based on the 2016 NYC Yellow Cab trip record data made available in Big Query on Google Cloud Platform. Its variables are as follows:\n",
    "![Dataset](https://cdn.exec.talentsprint.com/static/cds/NYC_Taxi_data_description_image.png)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "66CZ8AIPhmzt"
   },
   "source": [
    "Note that the features the ' Dask_MP_dataset.csv' file that is provided for this miniproject varies slightly in terms of included features, as compared to the original dataset described above. Please proceed with the provided csv file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ndQNKsjS7c04"
   },
   "source": [
    "## Grading = 10 Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "NH3jusKBx2LN"
   },
   "outputs": [],
   "source": [
    "#@title Install Dask dependencies and restart runtime\n",
    "!pip -qq install dask-ml\n",
    "!pip -qq install dask\n",
    "!pip -qq install dask[complete]\n",
    "!pip install --upgrade --force-reinstall dask distributed\n",
    "!pip -qq install mimesis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "powerful-preservation"
   },
   "source": [
    "#### Importing Necessary Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6tZDtdlmShI5"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import dask\n",
    "import dask.dataframe as dd\n",
    "import dask.array as da\n",
    "from dask_ml.linear_model import LinearRegression\n",
    "from dask_ml.model_selection import train_test_split\n",
    "from dask_ml.metrics import mean_squared_error, r2_score\n",
    "from dask.distributed import Client\n",
    "import time as time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from dask.distributed import Client, progress\n",
    "client = Client()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "anjQfD2Imqpg"
   },
   "outputs": [],
   "source": [
    "#@title Download the data\n",
    "!wget https://cdn.iisc.talentsprint.com/CDS/MiniProjects/Dask_MP_dataset.csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-a0QVo9kyVdj"
   },
   "source": [
    "#### Exercise 1: Read the dataset using dask library and compare the time of execution with pandas library. (1 Point)\n",
    "\n",
    "**Hint:** pass `dtype` for passenger_count as `int64`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AFyPyYzkyS0I"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yOPXzam_yOO7"
   },
   "source": [
    "#### Use pandas to read the dataset and compare the time taken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_GtHtAhLvJZB"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CFhWA9t11JhC"
   },
   "source": [
    "### Data Analysis\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BfwmgALALQ8g"
   },
   "source": [
    "#### Exercise 2: Drop the unnecessary columns. Also drop the duplicate rows and the rows having null values. (1 Point)\n",
    "\n",
    "**Hint:** Drop those columns which are not useful in EDA as well as model implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oY4VbXnyy7E0"
   },
   "outputs": [],
   "source": [
    "\"\"\" Drop unnecessary columns \"\"\"\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5C8YkabI1N4l"
   },
   "outputs": [],
   "source": [
    "\"\"\" Drop duplicate rows \"\"\"\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nZTAo8LafjU7"
   },
   "outputs": [],
   "source": [
    "\"\"\" drop NA rows \"\"\"\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "msJmBfyhL2fk"
   },
   "source": [
    "#### Exercise 3: Visualize the target variable, i.e., `fare_amount` to study the fare distribution, using a histogram density plot. Analyze the fare_amount distribution, try to visualize it for a range of [0, 60]. (1 Point)\n",
    "\n",
    "**Hint:** [sns.hisplot()](https://stackoverflow.com/questions/51027636/seaborn-histogram-with-bigdata/51027895) and use `.between` to plot the graph for given range\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WpvOEUW01WI_"
   },
   "outputs": [],
   "source": [
    "\"\"\" explore and plot the density plot of fare_amount \"\"\"\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CvPfB3yKiVQG"
   },
   "source": [
    "#### Observe the number of workers and cores running in your machine\n",
    "\n",
    "Initialize a client and observe how many workers are working and the number of cores utilizing for the given data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O85yDn3kRErR"
   },
   "outputs": [],
   "source": [
    "\"\"\" Initialize a client \"\"\"\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7a4Ifmf6y1fJ"
   },
   "source": [
    "### EDA based on Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fU-h_N6nby2k"
   },
   "source": [
    "#### Exercise 4: Extract day of the week (dow), hour, month and year from `pickup_datetime`. (1 Point)\n",
    "\n",
    "**Hint:** use `pd.to_datetime()` function as dask does not have this functionality in it.\n",
    "\n",
    "Remember to use `.compute()` while passing the dask dataframe in defined function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q4qP_G40gaX6"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iQlZJuvfkHmx"
   },
   "source": [
    "#### Exercise 5: a.) Plot the taxi trip by hour of the day  (0.5 Points)\n",
    "\n",
    "* Partition the data into segments using `dask.from_pandas()`\n",
    "\n",
    "* Plot the taxi trip for hour of the day. **Hint:** [sns.catplot](https://seaborn.pydata.org/generated/seaborn.catplot.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P3GzEYwzgiwq"
   },
   "outputs": [],
   "source": [
    "\"\"\" taxi trip repartition by hour of the day \"\"\"\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "33VcYhbln7br"
   },
   "source": [
    "#### Exercise 5: b.) Plot the taxi trip repartition by day of the week (dow) (0.5 Points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mf3fe9hnRFnL"
   },
   "outputs": [],
   "source": [
    "\"\"\" taxi trip repartition by day of the week \"\"\"\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lz2zTHmdslcy"
   },
   "source": [
    "#### Exercise 6: a.) Draw a plot between the target variable and passenger count and analyze it.  (0.5 Points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ATLNkBHqYrG_"
   },
   "outputs": [],
   "source": [
    "\"\"\" passenger count feature \"\"\"\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "31fJlk9StJuq"
   },
   "source": [
    "#### Exercise 6: b.) Draw a plot between the target variable and hour and analyze it. (0.5 Points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-DVhX3JZYytp"
   },
   "outputs": [],
   "source": [
    "\"\"\" fare amount by hour \"\"\"\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OGWcRiz72aRY"
   },
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WmfqpeZ0DcE8"
   },
   "source": [
    "#### Exercise 7: Compute the Haversine distance between pickup and dropoff point. (1 Point)\n",
    "\n",
    "* Convert the latitude and longitude co-rodinates to radians\n",
    "\n",
    "* Calculate the Haversine distance\n",
    "\n",
    "  **Hint:** [haversine_distances](https://towardsdatascience.com/heres-how-to-calculate-distance-between-2-geolocations-in-python-93ecab5bbba4)\n",
    "\n",
    "* Add the \"distance\" feature to the dataset and plot its distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w4oLk2DtR-kP"
   },
   "outputs": [],
   "source": [
    "\"\"\" distance feature \"\"\"\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6RHj-NePYi3y"
   },
   "outputs": [],
   "source": [
    "\"\"\" plot the distance feature (take distance < 50) \"\"\"\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uuQNBP0Ez3BR"
   },
   "source": [
    "### Show the plot between distance and fare amount\n",
    "\n",
    "**Hint:** [sns.scatterplot()](https://seaborn.pydata.org/generated/seaborn.scatterplot.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e8C5jkzcZOxO"
   },
   "outputs": [],
   "source": [
    "\"\"\" correlation between fare_amount and distance \"\"\"\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cpJMoALY0QgY"
   },
   "source": [
    "### Preparing dataset for model implementation\n",
    "\n",
    "**Note:** Use the above modified dataset for modelling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OTGatKRr3aeR"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sxy-7gBSRWGP"
   },
   "source": [
    "### Removing outliers from training set Based on Coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "THmnjXX-oGLv"
   },
   "source": [
    "#### Exercise 8: Remove the outliers using the given latitude and longitude features from the dataset. We need to analyze the data of taxi within New York City. (1 Point)\n",
    "\n",
    "**Hint:** Given the co-ordinates of New York city are Latitude: 40.7128° and Longitude: -74.0060°. You can include the pickup and drop off points such that there left and right value mean will be the given co-ordinate value.\n",
    "\n",
    "Also, choose nearest extreme values.\n",
    "\n",
    "Use `.between()` and pass left and right value attributes accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MsqHSsooRi4V"
   },
   "outputs": [],
   "source": [
    "\"\"\" remove the outliers in pickup latitude longitude and drop off latitude and longitude \"\"\"\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EPJSYwoT1is2"
   },
   "source": [
    "### Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BS-vF0vP1kLW"
   },
   "source": [
    "#### Exercise 9: Divide the data into train and test splits with X as feature variables and y as target variable  (1 Point)\n",
    "\n",
    "* Divide data into train test split with 70-30 ratio, Hint: `train_test_split()`\n",
    "\n",
    "* As dask functions operate lazily so, before calling `.fit()` function, call the dask dataframe with `.compute()`.\n",
    "* Convert X_train and y_train into array using `.values` as [dask's](https://ml.dask.org/modules/api.html) `.fit()` function takes array as attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dvQdA_T8t8uy"
   },
   "outputs": [],
   "source": [
    "\"\"\" select the target and feature variables and split the data into train and test \"\"\"\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zLz7SShbIQu3"
   },
   "source": [
    "#### Exercise 10: Predict the test data and calculate the mean squared error and r2 score. (1 Point)\n",
    "\n",
    "**Hint:** Remember to call `.compute()` function as dask functions operate lazily and convert the dask dataframe to `.values` (Array type) as suggested in above exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QqGNMROAWZgm"
   },
   "outputs": [],
   "source": [
    "\"\"\" predict the values \"\"\"\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wP1ZFckfux9j"
   },
   "outputs": [],
   "source": [
    "\"\"\" compute mean squared error and r2_score \"\"\"\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PBfQuoKdLUts"
   },
   "source": [
    "### Report Analysis\n",
    "* Discuss the pros and cons of using dask\n",
    "* Derive the insights and discuss\n",
    "* Comment on the performance metrics (MSE, $R^2$ score)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
